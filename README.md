# Short-Story-Assignment-CMPE-297

Medium Article : https://medium.com/@roshini.joga/can-we-trust-ai-agents-36e3f53e0ea5

PPT Slideshare Link: https://www.slideshare.net/slideshow/evaluation-and-benchmarking-of-llm-agents-full-slide-deck-2025-pptx/284513846

Youtube explanation: 

# ğŸ“˜ Short Story Assignment â€” Evaluation & Benchmarking of LLM Agents  
### A Summary, Analysis & Medium Article Based on the Survey  
### **â€œEvaluation and Benchmarking of LLM Agents: A Survey (KDD 2025)â€**

---

## ğŸ§‘â€ğŸ’» Author
**Your Name**  
Course: *[Course Name]*  
Semester: *[Semester]*  

---

## ğŸŒŸ Project Overview

This repository contains all deliverables for the Short Story Assignment based on the research survey:

**â€œEvaluation and Benchmarking of LLM Agents: A Survey (KDD 2025)â€**

The technical content of the survey was transformed into an accessible, human-centered short story delivered through:

- A **Medium.com article**
- A **SlideShare presentation**
- A **10â€“15 minute recorded video**
- This **GitHub repository** with all artifacts

---

## ğŸ“„ 1. Medium Article

ğŸ”— **Medium Article Link:**  
*<Insert Medium link here>*  

**Article Title:**  
*Can We Trust AI Agents? A Human-Centric Guide to Evaluating LLM Agents in 2025*

**Article Summary:**  
The article explains why agent evaluation is harder than traditional LLM evaluation, introduces the surveyâ€™s 2D taxonomy of evaluation objectives and processes, and highlights real-world challenges such as safety, reliability, compliance, memory, and planning. It includes my own analysis, insights, and visuals for better understanding.

---

## ğŸï¸ 2. SlideShare Presentation

ğŸ”— **SlideShare Link:**  
*<Insert SlideShare link here>*  

A 15-slide deck summarizing:

- Motivation behind evaluating agents  
- 2D taxonomy (WHAT to evaluate & HOW to evaluate)  
- Agent behavior, capabilities, reliability, and safety  
- Evaluation tooling, metrics, and enterprise challenges  
- Key takeaways and future directions  

---

## ğŸ¥ 3. Video Presentation (10â€“15 Minutes)

ğŸ”— **YouTube Video Link:**  
*<Insert YouTube link here>*  

**Video Overview:**  
This recorded presentation walks through the slides, explains the surveyâ€™s insights, demonstrates visuals, and provides a narrative summary of the short story.

---

## ğŸ“˜ 4. Paper Summary (Short Version)

The short story and materials are based on the surveyâ€™s key contributions:

### ğŸ”¹ 1. Evaluation Objectives â€” WHAT to measure
- Agent Behavior (task success, quality, latency, cost)  
- Agent Capabilities (tool use, planning, memory, collaboration)  
- Reliability (consistency, robustness, error handling)  
- Safety & Alignment (fairness, toxicity, compliance, privacy)

### ğŸ”¹ 2. Evaluation Process â€” HOW to evaluate
- Interaction Modes (static vs. dynamic evaluation)  
- Benchmarks & Datasets (web, tool-use, safety, reasoning)  
- Metrics (code-based, LLM-as-a-judge, human evaluation)  
- Evaluation Tooling (LangSmith, DeepEval, platforms)  
- Environments (sandbox, enterprise systems, simulations)

The survey highlights why evaluating agents is fundamentally harder than evaluating LLMs and why modern AI requires more rigorous safety, robustness, and multi-step assessment frameworks.

---

## ğŸ” 5. Additional Survey Papers Referenced (Optional)

If applicable, list any other surveys you referenced:

- LLM-as-a-Judge surveys  
- Agent safety and risk assessment surveys  
- Memory mechanisms in LLM agents  
- Multi-agent system surveys  

---

## ğŸ—ï¸ 6. Key Takeaways

- Agents operate in dynamic environments, so evaluation must go beyond accuracy.  
- Reliability, safety, and compliance are critical for enterprise deployment.  
- AgentOps and evaluation tooling are becoming essential parts of the development cycle.  
- Holistic, realistic, and scalable evaluation frameworks are the future of agent assessment.

---

## ğŸ§¾ 7. How to View Materials

### Medium Article  
Read directly using the link above.

### Slides  
View on SlideShare or open the PPTX/PDF inside the `/slides` section of this repository.

### Video  
Watch on YouTube or view the MP4 file in the `/video` section.

---

## ğŸ¤ 8. Acknowledgements

- Course Instructor: *Vijay erranti*  
- Original Paper Authors: Mahmoud Mohammadi et al. (KDD 2025)  
- Tools used: ChatGPT, Python, PPTX, Medium, SlideShare  

---

## ğŸ“¬ 9. Contact

For questions or collaboration:  
ğŸ“§ *Your Email*  
ğŸ”— *Your LinkedIn*

